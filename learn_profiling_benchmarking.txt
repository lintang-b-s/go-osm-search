
go test  -bench . -benchmem -cpuprofile prof.cpu

go tool pprof pkg.test prof.cpu

top10



list FreeFormQuery

result: 

Total: 17.03s
ROUTINE ======================== osm-search/pkg.(*Searcher).FreeFormQuery in /home/lintangbs/Documents/explore/software/project/personal/osm-search/pkg/searcher.go
      70ms      1.32s (flat, cum)  7.75% of Total
         .          .     91:func (se *Searcher) FreeFormQuery(query string, k int) ([]Node, error) {
         .          .     92:   if k == 0 {
         .          .     93:           k = 10
         .          .     94:   }
         .          .     95:   documentScore := make(map[int]float64) // menyimpan skor cosine tf-idf docs \dot tf-idf query
         .          .     96:   allPostings := make(map[int][]int)
         .          .     97:   docsPQ := NewMaxPriorityQueue[int, float64]()
         .          .     98:   heap.Init(docsPQ)
         .          .     99:
         .          .    100:   queryWordCount := make(map[int]int)
         .          .    101:
         .          .    102:   queryTermsID := []int{}
         .          .    103:
         .          .    104:   queryTerms := sastrawi.Tokenize(query)
         .          .    105:
         .          .    106:   // {{term1,term1OneEdit}, {term2, term2Edit}, ...}
         .          .    107:   allPossibleQueryTerms := make([][]int, len(queryTerms))
         .          .    108:   originalQueryTerms := make([]int, len(queryTerms))
         .          .    109:
         .          .    110:   for i, term := range queryTerms {
         .          .    111:           tokenizedTerm := stemmer.Stem(term)
         .          .    112:           isInVocab := se.TermIDMap.IsInVocabulary(tokenizedTerm)
         .          .    113:
         .          .    114:           originalQueryTerms[i] = se.TermIDMap.GetID(tokenizedTerm)
         .          .    115:
         .          .    116:           if !isInVocab {
         .          .    117:
         .       20ms    118:                   correctionOne, err := se.SpellCorrector.GetWordCandidates(tokenizedTerm, 1)
         .          .    119:                   if err != nil {
         .          .    120:                           return []Node{}, err
         .          .    121:                   }
         .      180ms    122:                   correctionTwo, err := se.SpellCorrector.GetWordCandidates(tokenizedTerm, 2)
         .          .    123:                   if err != nil {
         .          .    124:                           return []Node{}, err
         .          .    125:                   }
         .          .    126:                   allPossibleQueryTerms[i] = append(allPossibleQueryTerms[i], correctionOne...)
         .          .    127:                   allPossibleQueryTerms[i] = append(allPossibleQueryTerms[i], correctionTwo...)
         .          .    128:           } else {
         .          .    129:                   termID := se.TermIDMap.GetID(tokenizedTerm)
         .          .    130:                   allPossibleQueryTerms[i] = []int{termID}
         .          .    131:           }
         .          .    132:   }
         .          .    133:
         .          .    134:   allCorrectQueryCandidates := se.SpellCorrector.GetCorrectQueryCandidates(allPossibleQueryTerms)
         .       10ms    135:   correctQuery, err := se.SpellCorrector.GetCorrectSpellingSuggestion(allCorrectQueryCandidates, originalQueryTerms)
         .          .    136:
         .          .    137:   if err != nil {
         .          .    138:           return []Node{}, err
         .          .    139:   }
         .          .    140:
         .          .    141:   queryTermsID = append(queryTermsID, correctQuery...)
         .          .    142:
         .          .    143:   fanInFanOut := NewFanInFanOut[int, PostingsResult](len(queryTermsID))
         .          .    144:   fanInFanOut.GeneratePipeline(queryTermsID)
         .          .    145:
         .          .    146:   outs := []<-chan PostingsResult{}
         .          .    147:   for i := 0; i < NUM_WORKER_FANINFANOUT; i++ {
         .       10ms    148:           outs1 := fanInFanOut.FanOut(se.GetPostingListCon)
         .          .    149:           outs = append(outs, outs1)
         .          .    150:   }
         .          .    151:
         .          .    152:   results := fanInFanOut.FanIn(outs...)
         .          .    153:   for postingsRes := range results {
         .          .    154:           err := postingsRes.GetError()
         .          .    155:           if err != nil {
         .          .    156:                   return []Node{}, err
         .          .    157:           }
         .          .    158:           allPostings[postingsRes.GetTermID()] = postingsRes.GetPostings()
         .          .    159:           queryWordCount[postingsRes.GetTermID()] += 1
         .          .    160:   }
         .          .    161:
         .          .    162:   docWordCount := se.Idx.GetDocWordCount()
         .          .    163:
         .          .    164:   docNorm := make(map[int]float64)
         .          .    165:   queryNorm := 0.0
         .          .    166:   for qTermID, postings := range allPostings {
         .          .    167:           // iterate semua term di query, hitung tf-idf query dan tf-idf document, accumulate skor cosine di docScore
         .          .    168:           tfTermQuery := float64(queryWordCount[qTermID]) / float64(len(queryWordCount))
         .          .    169:           termOccurences := len(postings)
         .          .    170:           idfTermQuery := math.Log10(float64(se.Idx.GetDocsCount())) - math.Log10(float64(termOccurences))
         .          .    171:           tfIDFTermQuery := tfTermQuery * idfTermQuery
         .          .    172:           for _, docID := range postings {
         .          .    173:                   // compute tf-idf query dan document & compute cosine nya
         .          .    174:
      40ms      230ms    175:                   tf := 1.0 / float64(docWordCount[docID])
         .          .    176:                   termOccurences := len(postings)
      10ms       40ms    177:                   idf := math.Log10(float64(se.Idx.GetDocsCount())) - math.Log10(float64(termOccurences))
         .          .    178:                   tfIDFTermDoc := tf * idf
         .          .    179:
         .       80ms    180:                   documentScore[docID] += tfIDFTermDoc * tfIDFTermQuery
         .          .    181:
         .       90ms    182:                   docNorm[docID] += tfIDFTermDoc * tfIDFTermDoc
         .          .    183:           }
         .          .    184:           queryNorm += tfIDFTermQuery * tfIDFTermQuery
         .          .    185:   }
         .          .    186:
         .          .    187:   queryNorm = math.Sqrt(queryNorm)
         .          .    188:   for docID, norm := range docNorm {
         .       10ms    189:           docNorm[docID] = math.Sqrt(norm)
         .          .    190:   }
         .          .    191:
         .          .    192:   // normalize dengan cara dibagi dengan norm vector query & document
      10ms       30ms    193:   for docID, score := range documentScore {
      10ms       80ms    194:           documentScore[docID] = score / (queryNorm * docNorm[docID])
         .       70ms    195:           pqItem := NewPriorityQueueNode[int, float64](documentScore[docID], docID)
         .       30ms    196:           heap.Push(docsPQ, pqItem)
         .          .    197:
         .          .    198:   }
         .          .    199:
         .          .    200:   relevantDocs := []Node{}
         .          .    201:   for i := 0; i < k; i++ {
         .          .    202:           if docsPQ.Len() == 0 {
         .          .    203:                   break
         .          .    204:           }
         .          .    205:
         .          .    206:           heapItem := heap.Pop(docsPQ).(*priorityQueueNode[int, float64])
         .          .    207:           currRelDocID := heapItem.item
         .          .    208:           // doc, err := se.KV.GetNode(currRelDocID)
         .      440ms    209:           doc, err := se.DocStore.GetDoc(currRelDocID)
         .          .    210:           if err != nil {
         .          .    211:                   return []Node{}, err
         .          .    212:           }
         .          .    213:
         .          .    214:           relevantDocs = append(relevantDocs, doc)







 list GetDoc
result: 
 10ms      880ms (flat, cum)  5.17% of Total
         .          .    137:func (d *DocumentStore) GetDoc(docID int) (Node, error) {
         .          .    138:   compare := func(a, b int) int {
         .          .    139:           return a - b
         .          .    140:   }
         .          .    141:
         .          .    142:   blockPos := BinarySearch[int](d.BlockFirstDocID, docID, compare)
         .          .    143:   if blockPos > 0 {
         .          .    144:           blockPos-- // return posisi offset block dari docID
         .          .    145:   }
         .          .    146:
         .          .    147:   blockOffset := d.BlockOffsets[blockPos]
         .          .    148:
         .      860ms    149:   node, _, err := d.ReadDoc(blockOffset + d.DocOffsetInBlock[docID])
         .          .    150:   if err != nil {
         .          .    151:           return Node{}, err
         .          .    152:   }
      10ms       20ms    153:   d.DiskWriterReader.ResetFileSeek()
         .          .    154:   return node, nil
         .          .    155:}
         .          .    156:
         .          .    157:func (d *DocumentStore) SaveMeta() error {
         .          .    158:   metaFile, err := os.OpenFile(d.OutputDir+"/"+DOCUMENT_METADATA_FILENAME, os.O_CREATE|os.O_RDWR, 0666)
ROUTINE ======================== osm-search/pkg.(*DynamicIndex).GetDocsCount in /home/lintangbs/Documents/explore/software/project/personal/osm-search/pkg/inverted_index.go
      10ms       10ms (flat, cum) 0.059% of Total
         .          .    567:func (Idx *DynamicIndex) GetDocsCount() int {
      10ms       10ms    568:   return Idx.DocsCount
         .          .    569:}
         .          .    570:
         .          .    571:func (Idx *DynamicIndex) GetTermIDMap() IDMap {
         .          .    572:   return Idx.TermIDMap
         .          .    573:}





list ReadDoc

result: 
ROUTINE ======================== osm-search/pkg.(*DocumentStore).ReadDoc in /home/lintangbs/Documents/explore/software/project/personal/osm-search/pkg/document_store.go
      10ms      860ms (flat, cum)  5.05% of Total
         .          .     86:func (d *DocumentStore) ReadDoc(offset int) (Node, int, error) {
         .      140ms     87:   id, bytesWritten := d.DiskWriterReader.ReadUVarint(offset)
         .          .     88:   offset += bytesWritten
         .      200ms     89:   name, err := d.DiskWriterReader.ReadBytes(offset, 64)
         .          .     90:   if err != nil {
         .          .     91:           return Node{}, offset, err
         .          .     92:   }
         .          .     93:   offset += 64
         .      110ms     94:   lat, bytesWritten := d.DiskWriterReader.ReadFloat64(offset)
         .          .     95:   offset += bytesWritten
      10ms       90ms     96:   lon, bytesWritten := d.DiskWriterReader.ReadFloat64(offset)
         .          .     97:   offset += bytesWritten
         .       90ms     98:   address, err := d.DiskWriterReader.ReadBytes(offset, 128)
         .          .     99:   if err != nil {
         .          .    100:           return Node{}, offset, err
         .          .    101:   }
         .          .    102:   offset += 128
         .      100ms    103:   tipe, err := d.DiskWriterReader.ReadBytes(offset, 64)
         .          .    104:   if err != nil {
         .          .    105:           return Node{}, offset, err
         .          .    106:   }
         .          .    107:   offset += 64
         .      110ms    108:   city, err := d.DiskWriterReader.ReadBytes(offset, 32)
         .          .    109:   if err != nil {
         .          .    110:           return Node{}, offset, err
         .          .    111:   }
         .          .    112:   offset += 32
         .       20ms    113:   newNode := NewNode(int(id), string(name), lat, lon,
         .          .    114:           string(address), striReadAtng(tipe), string(city))
         .          .    115:   return newNode, offset, nil
         .          .    116:}
         .          .    117:
         .          .    118:func (d *DocumentStore) WriteDocs(docs []Node) {



 list ReadBytes

 result:

 ROUTINE ======================== osm-search/pkg.(*DiskWriterReader).ReadBytes in /home/lintangbs/Documents/explore/software/project/personal/osm-search/pkg/disk_writer_reader.go
         0      500ms (flat, cum)  2.94% of Total
         .          .     63:func (d *DiskWriterReader) ReadBytes(offset int, size int) ([]byte, error) {
         .      500ms     64:   buf, err := d.ReadAt(offset, size)
         .          .     65:   return buf, err
         .          .     66:}
         .          .     67:
         .          .     68:func (d *DiskWriterReader) LockBuffer() {
         .          .     69:   d.mu.Lock()



list ReadAt

result:
ROUTINE ======================== osm-search/pkg.(*DiskWriterReader).ReadAt in /home/lintangbs/Documents/explore/software/project/personal/osm-search/pkg/disk_writer_reader.go
      10ms      500ms (flat, cum)  2.94% of Total
         .          .    102:func (d *DiskWriterReader) ReadAt(offset int, fieldBytesSize int) ([]byte, error) {
         .       60ms    103:   _, err := d.File.Seek(int64(offset), 0)
         .      130ms    104:   reader := bufio.NewReader(d.File)
         .          .    105:
         .          .    106:   if err != nil {
         .          .    107:           return []byte{}, err
         .          .    108:   }
         .          .    109:
         .       10ms    110:   buf := make([]byte, fieldBytesSize)
         .          .    111:
      10ms       10ms    112:   for i := 0; i < fieldBytesSize; i++ {
         .      290ms    113:           b, err := reader.ReadByte()
         .          .    114:           if err != nil {
         .          .    115:                   return []byte{}, err
         .          .    116:           }
         .          .    117:           buf[i] = b
         .          .    118:   }


disasm ReadAt


list cmd useful:

go test -bench . -benchmem -cpuprofile prof.cpu -memprofile prof.mem
 
go tool pprof pkg.test prof.cpu

go tool pprof -alloc_objects pkg.test prof.mem

go-torch -u http

go build -gcflags=-m .


go tool pprof -http=":8081" [binary] [profile]

go tool pprof -http=":8081" pkg.test prof.cpu

go tool pprof -http=":8082" pkg.test prof.mem


disasm [namaFungsi]


optimization notes:
- file.read di diskwriterrider.readBytes() makan runtime paling banyak...
